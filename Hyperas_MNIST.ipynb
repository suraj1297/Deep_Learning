{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperas_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyP4UGQnkRrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install hyperas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTIkj_dvpvBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.datasets import mnist\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice, uniform\n",
        "from hyperopt import tpe, STATUS_OK,Trials "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8BWVS73qJqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading mnist dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "X_train = train_images.reshape(train_images.shape[0], -1)\n",
        "X_test = test_images.reshape(test_images.shape[0], -1)\n",
        "\n",
        "# Normalizing Datset\n",
        "X_train = X_train/255\n",
        "X_test =X_test/255\n",
        "  \n",
        "# Encoding Labels\n",
        "\n",
        "y_train = keras.utils.to_categorical(train_labels, 10)\n",
        "y_test = keras.utils.to_categorical(test_labels, 10)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD8v6qpuqnSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  \n",
        "  # define model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(512, input_dim=784, activation=\"relu\"))\n",
        "  model.add(Dropout({{uniform(0,1)}}))\n",
        "  model.add(Dense({{choice([512,256,1024])}}, activation={{choice([\"relu\",\"sigmoid\"])}}))\n",
        "  model.add(Dropout({{uniform(0,1)}}))\n",
        "  model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "  # compile model\n",
        "  model.compile(loss=\"categorical_crossentropy\",optimizer={{choice([\"adam\", \"rmsprop\", \"sgd\"])}}, metrics=[\"accuracy\"])\n",
        "  \n",
        "  # train model\n",
        "  result = model.fit(X_train, y_train, epochs={{choice([10,20])}}, batch_size=128, validation_split=0.1,verbose=5)\n",
        "  \n",
        "  # evaluate model\n",
        "#   score = model.evaluate(X_test, y_test, verbose=0)\n",
        "#   accuracy = score[1]\n",
        "  accuracy = np.amax(result.history['val_acc']) \n",
        "  print('Best validation acc of epoch:', accuracy)\n",
        "  \n",
        "  return {'loss': -accuracy, 'status': STATUS_OK, 'model': model}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h2y6qmF0s8W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "287d7967-1d43-422c-e36c-ee872922b5fb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%ls /gdrive"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "\u001b[0m\u001b[01;34m'My Drive'\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEnfKiQSrjHh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1f5fb7a5-af0d-4f36-8549-d75e0b641e78"
      },
      "source": [
        "best_run, best_model = optim.minimize(model=create_model, \n",
        "                                      data=data, \n",
        "                                      algo=tpe.suggest, \n",
        "                                      max_evals=5, \n",
        "                                      trials=Trials(),\n",
        "                                      notebook_name=os.path.join('..','gdrive',\"My Drive\", \"Colab Notebooks\",\"Hyperas_MNIST\"))\n"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Imports:\n",
            "#coding=utf-8\n",
            "\n",
            "try:\n",
            "    import keras\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.models import Sequential\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Dense, Dropout, Activation\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.datasets import mnist\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas import optim\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas.distributions import choice, uniform\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperopt import tpe, STATUS_OK, Trials\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from google.colab import drive\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import numpy as np\n",
            "except:\n",
            "    pass\n",
            "\n",
            ">>> Hyperas search space:\n",
            "\n",
            "def get_space():\n",
            "    return {\n",
            "        'Dropout': hp.uniform('Dropout', 0,1),\n",
            "        'Dense': hp.choice('Dense', [512,256,1024]),\n",
            "        'activation': hp.choice('activation', [\"relu\",\"sigmoid\"]),\n",
            "        'Dropout_1': hp.uniform('Dropout_1', 0,1),\n",
            "        'optimizer': hp.choice('optimizer', [\"adam\", \"rmsprop\", \"sgd\"]),\n",
            "        'epochs': hp.choice('epochs', [10,20]),\n",
            "    }\n",
            "\n",
            ">>> Data\n",
            "  1: \n",
            "  2: \n",
            "  3: # Loading mnist dataset\n",
            "  4: (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
            "  5: \n",
            "  6: X_train = train_images.reshape(train_images.shape[0], -1)\n",
            "  7: X_test = test_images.reshape(test_images.shape[0], -1)\n",
            "  8: \n",
            "  9: # Normalizing Datset\n",
            " 10: X_train = X_train/255\n",
            " 11: X_test =X_test/255\n",
            " 12: \n",
            " 13: # Encoding Labels\n",
            " 14: \n",
            " 15: y_train = keras.utils.to_categorical(train_labels, 10)\n",
            " 16: y_test = keras.utils.to_categorical(test_labels, 10)\n",
            " 17: \n",
            " 18: \n",
            " 19: \n",
            " 20: \n",
            ">>> Resulting replaced keras model:\n",
            "\n",
            "  1: def keras_fmin_fnct(space):\n",
            "  2: \n",
            "  3:   \n",
            "  4:   # define model\n",
            "  5:   model = Sequential()\n",
            "  6:   model.add(Dense(512, input_dim=784, activation=\"relu\"))\n",
            "  7:   model.add(Dropout(space['Dropout']))\n",
            "  8:   model.add(Dense(space['Dense'], activation=space['activation']))\n",
            "  9:   model.add(Dropout(space['Dropout_1']))\n",
            " 10:   model.add(Dense(10, activation=\"softmax\"))\n",
            " 11: \n",
            " 12:   # compile model\n",
            " 13:   model.compile(loss=\"categorical_crossentropy\",optimizer=space['optimizer'], metrics=[\"accuracy\"])\n",
            " 14:   \n",
            " 15:   # train model\n",
            " 16:   result = model.fit(X_train, y_train, epochs=space['epochs'], batch_size=128, validation_split=0.1,verbose=5)\n",
            " 17:   \n",
            " 18:   # evaluate model\n",
            " 19: #   score = model.evaluate(X_test, y_test, verbose=0)\n",
            " 20: #   accuracy = score[1]\n",
            " 21:   accuracy = np.amax(result.history['val_acc']) \n",
            " 22:   print('Best validation acc of epoch:', accuracy)\n",
            " 23:   \n",
            " 24:   return {'loss': -accuracy, 'status': STATUS_OK, 'model': model}\n",
            " 25: \n",
            "Train on 54000 samples, validate on 6000 samples\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Best validation acc of epoch:\n",
            "0.9490000003178914\n",
            "Train on 54000 samples, validate on 6000 samples\n",
            "Epoch 1/10\n",
            "Epoch 2/10\n",
            "Epoch 3/10\n",
            "Epoch 4/10\n",
            "Epoch 5/10\n",
            "Epoch 6/10\n",
            "Epoch 7/10\n",
            "Epoch 8/10\n",
            "Epoch 9/10\n",
            "Epoch 10/10\n",
            "Best validation acc of epoch:\n",
            "0.9836666661898296\n",
            "Train on 54000 samples, validate on 6000 samples\n",
            "Epoch 1/10\n",
            "Epoch 2/10\n",
            "Epoch 3/10\n",
            "Epoch 4/10\n",
            "Epoch 5/10\n",
            "Epoch 6/10\n",
            "Epoch 7/10\n",
            "Epoch 8/10\n",
            "Epoch 9/10\n",
            "Epoch 10/10\n",
            "Best validation acc of epoch:\n",
            "0.9815000001589457\n",
            "Train on 54000 samples, validate on 6000 samples\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Best validation acc of epoch:\n",
            "0.982333333492279\n",
            "Train on 54000 samples, validate on 6000 samples\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Best validation acc of epoch:\n",
            "0.9856666663487752\n",
            "100%|██████████| 5/5 [03:51<00:00, 50.58s/it, best loss: -0.9856666663487752]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJKnKvU8rjxw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "5f2e30f1-3187-4f99-c39a-81412c418dad"
      },
      "source": [
        "best_run"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Dense': 2,\n",
              " 'Dropout': 0.587606728324542,\n",
              " 'Dropout_1': 0.3746350041674067,\n",
              " 'activation': 0,\n",
              " 'epochs': 1,\n",
              " 'optimizer': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysyNIoys3Sxf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "ce00ba5b-b05b-4e7f-ca3d-adbd30cede17"
      },
      "source": [
        "import numpy as np\n",
        "# Metric/Performance\n",
        "_, accuracy = best_model.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
        "print(\"Accuracy on Test data is : \", accuracy)\n",
        "\n",
        "# Predictions\n",
        "pred = best_model.predict_classes(X_test, batch_size=128,verbose=0)\n",
        "\n",
        "for i in range(10):\n",
        "  print(\"Predicted : {} --> Expected : {}\".format(pred[i], np.argmax(y_test[i])))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on Test data is :  0.9831\n",
            "Predicted : 7 --> Expected : 7\n",
            "Predicted : 2 --> Expected : 2\n",
            "Predicted : 1 --> Expected : 1\n",
            "Predicted : 0 --> Expected : 0\n",
            "Predicted : 4 --> Expected : 4\n",
            "Predicted : 1 --> Expected : 1\n",
            "Predicted : 4 --> Expected : 4\n",
            "Predicted : 9 --> Expected : 9\n",
            "Predicted : 6 --> Expected : 5\n",
            "Predicted : 9 --> Expected : 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV7Cb2hA3X9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTWm_tMU5Jzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}